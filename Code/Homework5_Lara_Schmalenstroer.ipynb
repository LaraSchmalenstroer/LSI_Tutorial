{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI Tutorial Project 5\n",
    "\n",
    "## Lara Schmalenstroer\n",
    "\n",
    "### 09.12.2020\n",
    "\n",
    "\n",
    "## 5.1 and 5.2: manually predicting the results of a double digest on dna sequences 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path,'r') as file:\n",
    "    dna_seq1=file.read().replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\Lara\\\\LSITutorial\\\\dna.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutting_pos(rest_site):\n",
    "    index=rest_site.index('/')\n",
    "    return index\n",
    "\n",
    "def get_positions(sequence):\n",
    "    match_abc1=re.finditer(r\"A[A|G|C|T]TAAT\",sequence)\n",
    "    bases1=[]\n",
    "    positions1=[]\n",
    "    for m in match_abc1:\n",
    "        base=m.group()\n",
    "        bases1.append(base)\n",
    "        pos=m.start()\n",
    "        positions1.append(pos)\n",
    "    match_abc2=re.finditer(r\"GC[AG][^CG]TG\",sequence)\n",
    "    bases2=[]\n",
    "    positions2=[]\n",
    "    for m in match_abc2:\n",
    "        base=m.group()\n",
    "        bases2.append(base)\n",
    "        pos=m.start()\n",
    "        positions2.append(pos)\n",
    "    set1=[[bases1[i],positions1[i]] for i in range(len(bases1))]\n",
    "    set2=[[bases2[i],positions2[i]] for i in range(len(bases2))]\n",
    "    return [set1,set2]\n",
    "\n",
    "def get_fragment_dict(get_positions,sequence,cut_pos1,cut_pos2):\n",
    "    list_cutting_sites=get_positions(sequence)\n",
    "    seq_edit=[]\n",
    "    if re.search(r\"A[A|G|C|T]TAAT\",sequence):\n",
    "        for i in range(len(list_cutting_sites[0])):\n",
    "            seq_edit.append(re.sub(r\"A[A|G|C|T]TAAT\",list_cutting_sites[0][i][0][0:cut_pos1]+\";\"+list_cutting_sites[0]\\\n",
    "                                   [i][0][cut_pos1:],sequence))\n",
    "        seq1=seq_edit[-1]\n",
    "    if re.search(r\"GC[AG][^CG]TG\",sequence):\n",
    "        seq_list=[]\n",
    "        for i in range(len(list_cutting_sites[1])):\n",
    "            seq_list.append(re.sub(r\"GC[AG][^CG]TG\",list_cutting_sites[1][i][0][0:cut_pos2]+\";\"+list_cutting_sites[1]\\\n",
    "                                   [i][0][cut_pos2:],seq1))\n",
    "        seq_cutting_sites=seq_list[0]\n",
    "    else:\n",
    "        seq_cutting_sites=seq1\n",
    "    list_fragments=seq_cutting_sites.split(';')\n",
    "    return {len(list_fragments[i]):list_fragments[i] for i in range(len(list_fragments))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['ATTAAT', 162],\n",
       "  ['AGTAAT', 285],\n",
       "  ['ACTAAT', 428],\n",
       "  ['AGTAAT', 435],\n",
       "  ['AGTAAT', 618]],\n",
       " [['GCAATG', 471], ['GCGATG', 897]]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=get_positions(dna_seq1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{165: 'GTAGCCGCCAGCTCGGCCGCACGTCAGGGCGCGGGAGCGCGGAGCGAGTTTGGTTGCACTTACACCGGTACTTAAGCGCGGACCGGCGTGTCCTTGGACTTAGAGAGTGGGGACGTCCGGCTTCGGAGCGGGAGTGTTCGTTGTGCCAGCGACTAAAAAGAGAGT', 123: 'AATGCCACACCGTTGAAAAGGGAGGCAAGCACAAGACTGGGCCAAATCTCCATGGTCTCTTTGGGCGGAAGACAGGTCAGGCCCCTGGATACTCTTACACAGCCGCCAATAAGAACAAAGAGT', 143: 'AATGCATCATCTGGGGAGAGGATACACTGATGGAGTATTTGGAGAATCCCAAGAAGTACATCCCTGGAACAAAAATGATCTTTGTCGGCATTAAGAAGAAGGAAGAAAGGGCAGACTTAATAGCTTATCTCAAAAAAGCTAGT', 7: 'AATGAGT', 37: 'AATAATTGGCCACTGCCTTATTTATTACAAAACGCAA', 146: 'TGGTGGTCCCAGGCTGGTCTCAAACTCCTGAGCTCAAGCAATCCGTCCACTTGCCTTGGCTCCCCAAAGTGCTGGGATTACAGGCGTGAGCCACCAGGCCCTGCCTGGTTTTCAAATTCAGAAATCTTATTATTTAACCCAGAAGT', 280: 'AATCAGCCCAGTAGTAACTTAGGTTTAATTTTTTTTCAGGTTTAAAATTTTTCTCATTTATTTTTTCTGAGACGGAGTTTCGCCCTTTTCGCCCAGGCTGAGTACAGTGGTGCAATCTCACTGCAACCTCCGCCTTCCAGTTGCAAGTGATTCTCCTGCCTCAGCCTCCTGAGTAGCTGGGATTACAGGCACCCGCCACCACGCCTGGCTAATTTTTGTATTTTTAGTGGAGATGGTGTTTCACCATGTTGGCCAGACTGGTCTTGGACTCCTGACGCAA', 231: 'TGCGAGCGACCGAAACCCAAGCGGGGAGCATTCGAGTGGAGCCCGCGCTGGGTGGGAGGGCGGGGAGTGAAGACCCTGGACTGTGGTCAGACCGAGCTGGGCGAGTAACGGCTTGAGGTGCGGCGGAGCCCTAACTAGGGACAGGTATGGTCTCGGTCAGGGACTGGAGGCGGCTTGGATACAGATCCGAGGAGGAGGCGGCCTCTTCCGTAGTGGTTGCTGAAGGGCTAT'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "path='C:\\\\Users\\\\Lara\\\\LSITutorial\\\\dna.txt'\n",
    "with open(path,'r') as file:\n",
    "    dna_seq1=file.read().replace('\\n','')\n",
    "\n",
    "pos1=get_cutting_pos('ANT/AAT')\n",
    "pos2=get_cutting_pos('GCRW/TG')\n",
    "    \n",
    "dict_dna_seq1=get_fragment_dict(get_positions,dna_seq1,pos1,pos2)\n",
    "print(dict_dna_seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13: 'ATGTAACTGGAGT', 61: 'AATTGAAGTAACGTAATGTAAGGATGGTAAATGCCTAGTAAACCTTAAAAAAAAAAGGGGT'}\n"
     ]
    }
   ],
   "source": [
    "path2='C:\\\\Users\\\\Lara\\\\LSITutorial\\\\dna_seq.txt'\n",
    "\n",
    "with open(path2,'r') as file2:\n",
    "    dna_seq2=file2.read().replace('\\n','')\n",
    "\n",
    "\n",
    "dict_dna_seq2=get_fragment_dict(get_positions,dna_seq2,pos1,pos2)\n",
    "print(dict_dna_seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output_cutting_sites.txt','w') as file3:\n",
    "    file3.write('Double digest of restriction enzymes abc1 and abc2:\\n')\n",
    "    file3.write('Enzyme abc1: restriction site: ANT/AAT\\nEnzyme abc2: restriction site: GCRW/TG\\n\\n')\n",
    "    file3.write('Length of gene dna_seq1: '+str(len(dna_seq1))+' basepairs.\\n')\n",
    "    file3.write('Number of fragments: '+str(len(dict_dna_seq1))+'\\n\\n')\n",
    "    for key in dict_dna_seq1:\n",
    "        file3.write('Length of the fragment: '+str(key)+'\\nSequence: '+dict_dna_seq1[key]+'\\n\\n')\n",
    "    file3.write('Length of gene dna_seq2: '+str(len(dna_seq2))+' basepairs.\\n')\n",
    "    file3.write('Number of fragments: '+str(len(dict_dna_seq2))+'\\n\\n')\n",
    "    for key in dict_dna_seq2:\n",
    "        file3.write('Length of the fragment: '+str(key)+'\\nSequence: '+dict_dna_seq2[key]+'\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Loading of the file automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "path='C:\\\\Users\\\\Lara\\\\LSITutorial\\\\'\n",
    "os.chdir(path)\n",
    "pos1=get_cutting_pos('ANT/AAT')\n",
    "pos2=get_cutting_pos('GCRW/TG')\n",
    "with open(path+'Output_loop.txt','w') as out:\n",
    "    out.write('Double digest of restriction enzymes abc1 and abc2:\\n')\n",
    "    out.write('Length of gene dna_seq1: '+str(len(dna_seq1))+' basepairs.\\n')\n",
    "    out.write('Length of gene dna_seq2: '+str(len(dna_seq2))+' basepairs.\\n\\n')\n",
    "    out.write('Enzyme abc1: restriction site: ANT/AAT\\nEnzyme abc2: restriction site: GCRW/TG\\n\\n')\n",
    "for file in glob.glob('*dna*'):\n",
    "    dict_sequence={}\n",
    "    with open(file,'r') as data:\n",
    "        sequence=data.read().replace('\\n','')\n",
    "        dict_sequence=get_fragment_dict(get_positions,sequence,pos1,pos2)\n",
    "        with open(path+'Output_loop.txt','a') as out:\n",
    "            out.write('Name of file: '+file+'\\n')\n",
    "            out.write('Number of fragments: '+str(len(dict_sequence))+'\\n\\n')\n",
    "            for key in dict_sequence:\n",
    "                out.write('Length of the fragment: '+str(key)+'\\nSequence: '+dict_sequence[key]+'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
